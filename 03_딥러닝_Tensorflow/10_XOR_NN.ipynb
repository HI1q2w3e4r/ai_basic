{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xor_sigmoid\n",
    "# 2진 분류 : Logistic Regression\n",
    "# 활성화 함수 : sigmoid 함수 사용\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.random.set_seed(5)\n",
    "\n",
    "# train data set \n",
    "x_data = [[0,0],\n",
    "          [0,1],\n",
    "          [1,0],\n",
    "          [1,1]]\n",
    "\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "\n",
    "x_train = np.array(x_data,dtype=np.float32)\n",
    "y_train = np.array(y_data,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "#  (4,2) * (2,2) = (4,2)\n",
    "W1 = tf.Variable(tf.random.normal([2,2]),name = 'weight1')\n",
    "b1 = tf.Variable(tf.random.normal([2]), name = 'bias1')\n",
    "\n",
    "def layer1(X):\n",
    "    return  tf.sigmoid(tf.matmul(X,W1) + b1)  \n",
    "\n",
    "# Layer 2\n",
    "#  (4,2) * (2,1) = (4,1)\n",
    "W2 = tf.Variable(tf.random.normal([2,1]),name = 'weight2')\n",
    "b2 = tf.Variable(tf.random.normal([1]), name = 'bias2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis 예측 함수(방정식)  , H(x) = sigmoid(W * X + b)\n",
    "# tf.sigmoid : tf.div(1., 1. + tf.exp(tf.matmul(X,W)))\n",
    "def hypothesis(X):\n",
    "    return  tf.sigmoid(tf.matmul(layer1(X),W2) + b2 )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용함수 : logloss, 2진 분류 모델\n",
    "def cost_func():\n",
    "    # cost = tf.reduce_mean(tf.square(hypothesis(x_train) - y_train)) # 회귀 모델\n",
    "\n",
    "    cost = -tf.reduce_mean(y_train*tf.math.log(hypothesis(x_train)) + \n",
    "                          (1 - y_train)*tf.math.log(1 - hypothesis(x_train)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# learning_rate(학습율)을 0.01 로 설정하여 optimizer객체를 생성\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Start Learning!!\n",
      "0000 cost:[ 0.7021535 ]  W: [[-0.20026703 -0.9303336 ]\n",
      " [-0.05959957 -0.72258526]]  b: [0.20657825 0.8305367 ]\n",
      "0100 cost:[ 0.64687014 ]  W: [[-0.57563096 -1.9478204 ]\n",
      " [-0.33180177 -1.7519976 ]]  b: [0.22770831 0.01919761]\n",
      "0200 cost:[ 0.51232815 ]  W: [[-1.3136894 -3.276814 ]\n",
      " [-1.2115136 -3.0818226]]  b: [1.5556365 0.7471327]\n",
      "0300 cost:[ 0.29046947 ]  W: [[-2.5063674 -4.3613505]\n",
      " [-2.462523  -4.179632 ]]  b: [3.5375388 1.5050306]\n",
      "0400 cost:[ 0.15810695 ]  W: [[-3.321316  -5.0720162]\n",
      " [-3.284801  -4.8969197]]  b: [4.8384356 1.969765 ]\n",
      "0500 cost:[ 0.098320864 ]  W: [[-3.8367662 -5.5385656]\n",
      " [-3.8027306 -5.3673167]]  b: [5.6539173 2.2598033]\n",
      "0600 cost:[ 0.06778896 ]  W: [[-4.1971564 -5.8737283]\n",
      " [-4.1644707 -5.7050195]]  b: [6.2206273 2.4608808]\n",
      "0700 cost:[ 0.050050575 ]  W: [[-4.470299  -6.132241 ]\n",
      " [-4.438529  -5.9653316]]  b: [6.648024  2.6120965]\n",
      "0800 cost:[ 0.038731076 ]  W: [[-4.68895   -6.341649 ]\n",
      " [-4.6578774 -6.1760907]]  b: [6.9887667 2.7323232]\n",
      "0900 cost:[ 0.031002566 ]  W: [[-4.8707695 -6.5172634]\n",
      " [-4.840265  -6.3527613]]  b: [7.271157  2.8317142]\n",
      "1000 cost:[ 0.025454197 ]  W: [[-5.026209  -6.6683474]\n",
      " [-4.9961796 -6.504695 ]]  b: [7.51189   2.9162605]\n",
      "1100 cost:[ 0.021314602 ]  W: [[-5.1619086 -6.8008904]\n",
      " [-5.132291  -6.6379356]]  b: [7.7215414 2.989746 ]\n",
      "1200 cost:[ 0.018130828 ]  W: [[-5.2823296 -6.9189677]\n",
      " [-5.253074  -6.7565985]]  b: [7.907201  3.0547132]\n",
      "1300 cost:[ 0.015621284 ]  W: [[-5.3906064 -7.025472 ]\n",
      " [-5.361675  -6.8636017]]  b: [8.073834 3.112932]\n",
      "1400 cost:[ 0.013602881 ]  W: [[-5.4890165 -7.1225247]\n",
      " [-5.460377  -6.961083 ]]  b: [8.225042  3.1656916]\n",
      "1500 cost:[ 0.011951717 ]  W: [[-5.5792675 -7.2117248]\n",
      " [-5.550896  -7.0506577]]  b: [8.363525 3.213946]\n",
      "1600 cost:[ 0.0105813965 ]  W: [[-5.662673  -7.2943096]\n",
      " [-5.6345468 -7.133572 ]]  b: [8.491338  3.2584326]\n",
      "1700 cost:[ 0.009430071 ]  W: [[-5.7402515 -7.3712506]\n",
      " [-5.712353  -7.2108064]]  b: [8.610093  3.2997231]\n",
      "1800 cost:[ 0.008452263 ]  W: [[-5.812825  -7.4433317]\n",
      " [-5.7851353 -7.283139 ]]  b: [8.721069  3.3382702]\n",
      "1900 cost:[ 0.007613993 ]  W: [[-5.8810487 -7.5111737]\n",
      " [-5.85356   -7.351216 ]]  b: [8.825305 3.374445]\n",
      "2000 cost:[ 0.0068893884 ]  W: [[-5.945469  -7.575301 ]\n",
      " [-5.9181676 -7.4155564]]  b: [8.923644  3.4085467]\n",
      "2100 cost:[ 0.0062583787 ]  W: [[-6.0065346 -7.6361494]\n",
      " [-5.9794083 -7.476597 ]]  b: [9.016794  3.4408236]\n",
      "2200 cost:[ 0.0057052616 ]  W: [[-6.0646214 -7.69408  ]\n",
      " [-6.037662  -7.534704 ]]  b: [9.105336  3.4714816]\n",
      "2300 cost:[ 0.0052175783 ]  W: [[-6.1200476 -7.7493997]\n",
      " [-6.09325   -7.590188 ]]  b: [9.1897745 3.5006976]\n",
      "2400 cost:[ 0.0047852024 ]  W: [[-6.173089  -7.802378 ]\n",
      " [-6.1464434 -7.643315 ]]  b: [9.270528  3.5286224]\n",
      "2500 cost:[ 0.004400069 ]  W: [[-6.2239776 -7.8532386]\n",
      " [-6.1974745 -7.694313 ]]  b: [9.34796   3.5553808]\n",
      "2600 cost:[ 0.00405545 ]  W: [[-6.2729154 -7.902179 ]\n",
      " [-6.2465515 -7.743381 ]]  b: [9.422389  3.5810866]\n",
      "2700 cost:[ 0.003745861 ]  W: [[-6.3200803 -7.949371 ]\n",
      " [-6.293848  -7.790691 ]]  b: [9.494084  3.6058362]\n",
      "2800 cost:[ 0.0034667365 ]  W: [[-6.3656225 -7.9949656]\n",
      " [-6.3395176 -7.8363953]]  b: [9.563286  3.6297128]\n",
      "2900 cost:[ 0.0032141805 ]  W: [[-6.4096828 -8.039096 ]\n",
      " [-6.383701  -7.8806267]]  b: [9.630209  3.6527913]\n",
      "3000 cost:[ 0.0029849736 ]  W: [[-6.452379  -8.081878 ]\n",
      " [-6.4265146 -7.923505 ]]  b: [9.695033  3.6751351]\n",
      "3100 cost:[ 0.0027763357 ]  W: [[-6.4938183 -8.123418 ]\n",
      " [-6.4680676 -7.9651346]]  b: [9.757925  3.6968048]\n",
      "3200 cost:[ 0.002585953 ]  W: [[-6.534096 -8.163809]\n",
      " [-6.508457 -8.00561 ]]  b: [9.819036 3.717851]\n",
      "3300 cost:[ 0.0024117238 ]  W: [[-6.573298  -8.2031355]\n",
      " [-6.547767  -8.045013 ]]  b: [9.878496  3.7383187]\n",
      "3400 cost:[ 0.0022519822 ]  W: [[-6.6115    -8.241473 ]\n",
      " [-6.5860763 -8.083423 ]]  b: [9.93642   3.7582514]\n",
      "3500 cost:[ 0.0021052277 ]  W: [[-6.648771  -8.278888 ]\n",
      " [-6.6234493 -8.120907 ]]  b: [9.992917  3.7776856]\n",
      "3600 cost:[ 0.0019700357 ]  W: [[-6.6851754 -8.31544  ]\n",
      " [-6.6599503 -8.157525 ]]  b: [10.048084   3.7966552]\n",
      "3700 cost:[ 0.0018453724 ]  W: [[-6.7207665 -8.35119  ]\n",
      " [-6.6956377 -8.193337 ]]  b: [10.102007   3.8151913]\n",
      "3800 cost:[ 0.0017301434 ]  W: [[-6.7556    -8.386186 ]\n",
      " [-6.7305636 -8.228392 ]]  b: [10.154767  3.833321]\n",
      "3900 cost:[ 0.0016234354 ]  W: [[-6.7897186 -8.420473 ]\n",
      " [-6.764774  -8.262735 ]]  b: [10.206434  3.851071]\n",
      "4000 cost:[ 0.0015245737 ]  W: [[-6.823166  -8.454097 ]\n",
      " [-6.7983146 -8.296411 ]]  b: [10.257076   3.8684618]\n",
      "4100 cost:[ 0.0014327654 ]  W: [[-6.855986  -8.487092 ]\n",
      " [-6.8312216 -8.329456 ]]  b: [10.306756   3.8855164]\n",
      "4200 cost:[ 0.0013474562 ]  W: [[-6.888212  -8.519497 ]\n",
      " [-6.8635325 -8.36191  ]]  b: [10.355524   3.9022534]\n",
      "4300 cost:[ 0.001268018 ]  W: [[-6.919876 -8.551344]\n",
      " [-6.895278 -8.393804]]  b: [10.403434  3.918691]\n",
      "4400 cost:[ 0.001193987 ]  W: [[-6.951008  -8.5826645]\n",
      " [-6.926492  -8.425165 ]]  b: [10.450532   3.9348452]\n",
      "4500 cost:[ 0.001124929 ]  W: [[-6.9816384 -8.613485 ]\n",
      " [-6.9572034 -8.456025 ]]  b: [10.4968605  3.9507325]\n",
      "4600 cost:[ 0.0010604255 ]  W: [[-7.011791  -8.64383  ]\n",
      " [-6.9874363 -8.486409 ]]  b: [10.542463   3.9663663]\n",
      "4700 cost:[ 0.0010001475 ]  W: [[-7.0414906 -8.673725 ]\n",
      " [-7.017214  -8.516343 ]]  b: [10.587373   3.9817579]\n",
      "4800 cost:[ 0.0009437213 ]  W: [[-7.0707626 -8.703193 ]\n",
      " [-7.04656   -8.545842 ]]  b: [10.631625   3.9969203]\n",
      "4900 cost:[ 0.0008908927 ]  W: [[-7.0996222 -8.732254 ]\n",
      " [-7.075497  -8.574934 ]]  b: [10.675252  4.011865]\n",
      "5000 cost:[ 0.00084139255 ]  W: [[-7.1280947 -8.760926 ]\n",
      " [-7.10404   -8.603636 ]]  b: [10.718284  4.026602]\n",
      "5100 cost:[ 0.00079492235 ]  W: [[-7.1561937 -8.789226 ]\n",
      " [-7.132211  -8.631966 ]]  b: [10.760747   4.0411415]\n",
      "5200 cost:[ 0.0007513174 ]  W: [[-7.1839385 -8.817172 ]\n",
      " [-7.160026  -8.659943 ]]  b: [10.802666   4.0554924]\n",
      "5300 cost:[ 0.00071033894 ]  W: [[-7.2113414 -8.84478  ]\n",
      " [-7.1874976 -8.687574 ]]  b: [10.844068  4.069662]\n",
      "5400 cost:[ 0.00067185226 ]  W: [[-7.2384176 -8.8720665]\n",
      " [-7.214644  -8.714885 ]]  b: [10.884972   4.0836577]\n",
      "5500 cost:[ 0.00063564844 ]  W: [[-7.26518  -8.899038]\n",
      " [-7.241476 -8.741884]]  b: [10.925403  4.097489]\n",
      "5600 cost:[ 0.0006015632 ]  W: [[-7.291654  -8.925712 ]\n",
      " [-7.2680144 -8.76858  ]]  b: [10.965374  4.111163]\n",
      "5700 cost:[ 0.0005694621 ]  W: [[-7.3178287 -8.952102 ]\n",
      " [-7.294257  -8.794992 ]]  b: [11.004912  4.124682]\n",
      "5800 cost:[ 0.00053921074 ]  W: [[-7.3437357 -8.978218 ]\n",
      " [-7.3202314 -8.821125 ]]  b: [11.044026  4.138058]\n",
      "5900 cost:[ 0.0005106898 ]  W: [[-7.3693705 -9.004066 ]\n",
      " [-7.3459315 -8.8469925]]  b: [11.082739   4.1512885]\n",
      "6000 cost:[ 0.0004838244 ]  W: [[-7.3947616 -9.029658 ]\n",
      " [-7.3713803 -8.872607 ]]  b: [11.121059   4.1643906]\n",
      "6100 cost:[ 0.00045846554 ]  W: [[-7.4198856 -9.055013 ]\n",
      " [-7.396577  -8.897973 ]]  b: [11.159009   4.1773534]\n",
      "6200 cost:[ 0.0004345235 ]  W: [[-7.444797 -9.080121]\n",
      " [-7.421546 -8.923103]]  b: [11.196594   4.1901975]\n",
      "6300 cost:[ 0.0004119237 ]  W: [[-7.4694734 -9.105006 ]\n",
      " [-7.4462795 -8.948001 ]]  b: [11.233831   4.2029214]\n",
      "6400 cost:[ 0.0003905617 ]  W: [[-7.4939127 -9.129673 ]\n",
      " [-7.4707828 -8.972682 ]]  b: [11.270733   4.2155185]\n",
      "6500 cost:[ 0.00037037782 ]  W: [[-7.5181556 -9.1541195]\n",
      " [-7.495083  -8.997148 ]]  b: [11.307308   4.2280083]\n",
      "6600 cost:[ 0.0003512825 ]  W: [[-7.5421963 -9.178361 ]\n",
      " [-7.519171  -9.021402 ]]  b: [11.34357    4.2403936]\n",
      "6700 cost:[ 0.00033326077 ]  W: [[-7.566027  -9.202403 ]\n",
      " [-7.5430603 -9.045457 ]]  b: [11.379523  4.252669]\n",
      "6800 cost:[ 0.00031617848 ]  W: [[-7.5896645 -9.226252 ]\n",
      " [-7.566753  -9.069318 ]]  b: [11.415181   4.2648396]\n",
      "6900 cost:[ 0.0003000504 ]  W: [[-7.6130853 -9.249917 ]\n",
      " [-7.5902452 -9.092992 ]]  b: [11.450561  4.276899]\n",
      "7000 cost:[ 0.00028475732 ]  W: [[-7.6363597 -9.273397 ]\n",
      " [-7.6135726 -9.116484 ]]  b: [11.485656  4.288875]\n",
      "7100 cost:[ 0.00027028425 ]  W: [[-7.6594534 -9.296702 ]\n",
      " [-7.6367188 -9.139797 ]]  b: [11.520479  4.300759]\n",
      "7200 cost:[ 0.00025658644 ]  W: [[-7.6823697 -9.319831 ]\n",
      " [-7.659688  -9.162932 ]]  b: [11.555042   4.3125525]\n",
      "7300 cost:[ 0.00024358937 ]  W: [[-7.705123 -9.34279 ]\n",
      " [-7.682493 -9.185902]]  b: [11.589354  4.324258]\n",
      "7400 cost:[ 0.00023130787 ]  W: [[-7.7277107 -9.36559  ]\n",
      " [-7.7051215 -9.208711 ]]  b: [11.623412   4.3358746]\n",
      "7500 cost:[ 0.00021962271 ]  W: [[-7.750137  -9.388233 ]\n",
      " [-7.7276073 -9.231359 ]]  b: [11.65723    4.3474073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600 cost:[ 0.00020857855 ]  W: [[-7.7724075 -9.410713 ]\n",
      " [-7.7499313 -9.253847 ]]  b: [11.690812  4.358857]\n",
      "7700 cost:[ 0.00019814562 ]  W: [[-7.7945247 -9.433053 ]\n",
      " [-7.7721047 -9.276195 ]]  b: [11.72417    4.3702254]\n",
      "7800 cost:[ 0.0001882046 ]  W: [[-7.8164964 -9.4552355]\n",
      " [-7.7941275 -9.298381 ]]  b: [11.757297   4.3815107]\n",
      "7900 cost:[ 0.00017881514 ]  W: [[-7.83831   -9.477286 ]\n",
      " [-7.8160095 -9.320437 ]]  b: [11.79021   4.392723]\n",
      "8000 cost:[ 0.00016988777 ]  W: [[-7.859981  -9.4991865]\n",
      " [-7.8377337 -9.342341 ]]  b: [11.822919   4.4038434]\n",
      "8100 cost:[ 0.0001614076 ]  W: [[-7.881544  -9.520962 ]\n",
      " [-7.8593473 -9.3641205]]  b: [11.855414   4.4149156]\n",
      "8200 cost:[ 0.0001533746 ]  W: [[-7.9029727 -9.542589 ]\n",
      " [-7.8808227 -9.385754 ]]  b: [11.887706   4.4259157]\n",
      "8300 cost:[ 0.00014574407 ]  W: [[-7.924268 -9.564092]\n",
      " [-7.902166 -9.407259]]  b: [11.919796   4.4368525]\n",
      "8400 cost:[ 0.00013850105 ]  W: [[-7.945429  -9.58547  ]\n",
      " [-7.9233747 -9.428642 ]]  b: [11.951694   4.4477186]\n",
      "8500 cost:[ 0.00013163069 ]  W: [[-7.966459 -9.606711]\n",
      " [-7.944451 -9.449885]]  b: [11.983402  4.45851 ]\n",
      "8600 cost:[ 0.00012510314 ]  W: [[-7.9873676 -9.627836 ]\n",
      " [-7.965413  -9.471011 ]]  b: [12.014921   4.4692407]\n",
      "8700 cost:[ 0.00011890349 ]  W: [[-8.008175  -9.648842 ]\n",
      " [-7.9862328 -9.492023 ]]  b: [12.04626    4.4799004]\n",
      "8800 cost:[ 0.000113031754 ]  W: [[-8.028851 -9.669724]\n",
      " [-8.006966 -9.512911]]  b: [12.077412  4.490511]\n",
      "8900 cost:[ 0.000107472995 ]  W: [[-8.049396 -9.690488]\n",
      " [-8.027573 -9.533674]]  b: [12.108389  4.50106 ]\n",
      "9000 cost:[ 0.00010216762 ]  W: [[-8.069832 -9.711141]\n",
      " [-8.048054 -9.554329]]  b: [12.139197  4.511536]\n",
      "9100 cost:[ 9.714543e-05 ]  W: [[-8.090162 -9.731683]\n",
      " [-8.068432 -9.574873]]  b: [12.169836  4.521963]\n",
      "9200 cost:[ 9.2346796e-05 ]  W: [[-8.110374 -9.752117]\n",
      " [-8.0887   -9.595307]]  b: [12.200306   4.5323358]\n",
      "9300 cost:[ 8.780153e-05 ]  W: [[-8.130488 -9.772445]\n",
      " [-8.108851 -9.615636]]  b: [12.23061    4.5426383]\n",
      "9400 cost:[ 8.349472e-05 ]  W: [[-8.150501 -9.792659]\n",
      " [-8.128906 -9.635851]]  b: [12.2607565  4.5528927]\n",
      "9500 cost:[ 7.938166e-05 ]  W: [[-8.170393 -9.812766]\n",
      " [-8.148851 -9.655961]]  b: [12.290744  4.563095]\n",
      "9600 cost:[ 7.5477255e-05 ]  W: [[-8.190188 -9.832772]\n",
      " [-8.168696 -9.675967]]  b: [12.32057   4.573239]\n",
      "9700 cost:[ 7.179639e-05 ]  W: [[-8.209878  -9.852679 ]\n",
      " [-8.1884365 -9.695872 ]]  b: [12.350254  4.583319]\n",
      "9800 cost:[ 6.829437e-05 ]  W: [[-8.22948  -9.872486]\n",
      " [-8.208078 -9.715678]]  b: [12.379778   4.5933557]\n",
      "9900 cost:[ 6.4941385e-05 ]  W: [[-8.248975 -9.892194]\n",
      " [-8.227628 -9.735385]]  b: [12.409158   4.6033416]\n",
      "10000 cost:[ 6.175233e-05 ]  W: [[-8.268385 -9.911804]\n",
      " [-8.247078 -9.754995]]  b: [12.438388   4.6132865]\n",
      "****** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "print('****** Start Learning!!')\n",
    "for step in range(10001):\n",
    "    # cost를 minimize 한다\n",
    "    optimizer.minimize(cost_func,var_list=[W1,b1,W2,b2]) # W,b를 업데이트\n",
    "    if step % 100 == 0:\n",
    "        print('%04d'%step,'cost:[',cost_func().numpy(),']',\n",
    "             ' W:',W1.numpy(),' b:',b1.numpy())\n",
    "        \n",
    "print('****** Learning Finished!!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight과 bias 출력\n",
    "print('Weight:',W1.numpy())\n",
    "print('bias:', b1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis:\n",
      " [[7.1297203e-05]\n",
      " [9.9994075e-01]\n",
      " [9.9994135e-01]\n",
      " [5.7793830e-05]] \n",
      "Predict:\n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# predict : test model\n",
    "# accuracy computation (정확도 측정)\n",
    "def predict(X):\n",
    "    return tf.cast(hypothesis(X) > 0.5, dtype = tf.float32)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predict(x_train),y_train),\n",
    "                                     dtype = tf.float64))\n",
    "print(\"Hypothesis:\\n\",hypothesis(x_train).numpy(), \n",
    "      \"\\nPredict:\\n\",predict(x_train).numpy(),\n",
    "      \"\\nAccuracy:\",accuracy.numpy())   # Accuracy: 0.5   1층으로는 \n",
    "                                        # Accuracy: 1.0   2층으로 해결\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
