{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-classification\n",
    ": multi-nomial classification (다중 분류) : Y값의 범주가 3개 이상인 분류\n",
    "#### 활성화 함수(Activation function) 으로 softmax함수 가 사용된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.random.set_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data set :\n",
    "# x_data :  [N,4]  --> [8,4]\n",
    "x_data = [[1,2,1,1],\n",
    "          [2,1,3,2],\n",
    "          [3,1,3,4],\n",
    "          [4,1,5,5],\n",
    "          [1,7,5,5],\n",
    "          [1,2,5,6],\n",
    "          [1,6,6,6],\n",
    "          [1,7,7,7]]\n",
    "\n",
    "# y_data : [N,3] --> [8,3]\n",
    "y_data = [[0,0,1],  # [2]\n",
    "          [0,0,1],  # [2]\n",
    "          [0,0,1],  # [2]\n",
    "          [0,1,0],  # [1]\n",
    "          [0,1,0],  # [1]\n",
    "          [0,1,0],  # [1]\n",
    "          [1,0,0],  # [0]\n",
    "          [1,0,0]]  # [0]\n",
    "\n",
    "x_train = np.array(x_data,dtype=np.float32)\n",
    "y_train = np.array(y_data,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 3 # 분류(class) 갯수\n",
    "\n",
    "# 변수 초기화 : weight, bias\n",
    "# (8,4) * (4,3) = (8,3)\n",
    "W = tf.Variable(tf.random.normal([4,nb_classes]), name = 'weight')\n",
    "b = tf.Variable(tf.random.normal([nb_classes]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 함수(hypothesis) : H(X) = softmax(X*W + b)\n",
    "def logits(X):\n",
    "    return tf.matmul(X,W) + b\n",
    "\n",
    "def hypothesis(X):\n",
    "    return tf.nn.softmax(logits(X))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 비용 함수 구현 방법 1: log함수를 사용하여 수식을 직접 표현\n",
    "# def cost_func():\n",
    "#     cost = tf.reduce_mean(-tf.reduce_sum(y_train*tf.math.log(hypothesis(x_train)),\n",
    "#                                          axis=1))\n",
    "#     return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용함수 구현 방법 2 : tf.nn.softmax_cross_entropy_with_logits() 함수 사용\n",
    "def cost_func():\n",
    "    cost_i = tf.nn.softmax_cross_entropy_with_logits(logits = logits(x_train),\n",
    "                                             labels = y_train)\n",
    "    cost =  tf.reduce_mean(cost_i)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# learning_rate(학습율)을 0.01 로 설정하여 optimizer객체를 생성\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Start Learning!!\n",
      "0000 cost:[ 5.9294786 ]  W: [[-0.17030679 -0.94028634 -0.04964045]\n",
      " [-0.7325406   1.3331522  -0.628548  ]\n",
      " [ 0.86406636 -0.07899956  2.4388697 ]\n",
      " [ 0.77250797  1.2759615   0.9701489 ]]  b: [0.2365285  0.8206551  0.73660946]\n",
      "0100 cost:[ 1.1552231 ]  W: [[-0.5470718  -0.03807735 -0.24936767]\n",
      " [-0.02111381  0.53332376 -0.75196683]\n",
      " [ 1.3003658   0.11232628  2.0026753 ]\n",
      " [ 1.1551087   1.6565033   0.5315274 ]]  b: [0.28334293 0.65043896 0.8277265 ]\n",
      "0200 cost:[ 0.67908156 ]  W: [[-0.91939455  0.13888852  0.01354875]\n",
      " [ 0.17423075  0.14159855 -0.43874633]\n",
      " [ 1.3674178   0.38877195  1.8341357 ]\n",
      " [ 1.1541306   1.932615    0.42247915]]  b: [-0.11689189 -0.17410971  1.5440289 ]\n",
      "0300 cost:[ 0.55539304 ]  W: [[-1.1160616   0.1323512   0.25641182]\n",
      " [ 0.1963242   0.04641756 -0.3066862 ]\n",
      " [ 1.4728361   0.5946489   1.6559124 ]\n",
      " [ 1.2038623   1.9983065   0.3519727 ]]  b: [-0.4423253 -0.716647   2.0596278]\n",
      "0400 cost:[ 0.4929726 ]  W: [[-1.2841822   0.1575776   0.43241403]\n",
      " [ 0.18301247  0.02505389 -0.23821715]\n",
      " [ 1.5831243   0.74726456  1.4937586 ]\n",
      " [ 1.2480973   1.9794453   0.32027748]]  b: [-0.74658287 -1.04525     2.4589043 ]\n",
      "0500 cost:[ 0.44993573 ]  W: [[-1.4420841   0.20132688  0.577626  ]\n",
      " [ 0.16684902  0.01865042 -0.19182739]\n",
      " [ 1.6939706   0.86850977  1.3433052 ]\n",
      " [ 1.2768852   1.9389911   0.31095558]]  b: [-1.051309  -1.257513   2.8059857]\n",
      "0600 cost:[ 0.41587573 ]  W: [[-1.5961274   0.25433728  0.7091132 ]\n",
      " [ 0.15442161  0.0139949  -0.15666975]\n",
      " [ 1.806453    0.96550184  1.2007442 ]\n",
      " [ 1.2918668   1.8968441   0.31457186]]  b: [-1.3652685 -1.3918784  3.1266365]\n",
      "0700 cost:[ 0.38674682 ]  W: [[-1.7495644   0.31398863  0.8334277 ]\n",
      " [ 0.14479464  0.00969124 -0.12812772]\n",
      " [ 1.9218088   1.0411787   1.0637376 ]\n",
      " [ 1.2967906   1.8584228   0.32562363]]  b: [-1.690454  -1.4699707  3.4328542]\n",
      "0800 cost:[ 0.36069128 ]  W: [[-1.9042255   0.3794582   0.95359963]\n",
      " [ 0.1364838   0.00616822 -0.10385014]\n",
      " [ 2.0405056   1.0979615   0.9308785 ]\n",
      " [ 1.2946192   1.8253158   0.34084266]]  b: [-2.0259688 -1.5073407  3.731145 ]\n",
      "0900 cost:[ 0.336813 ]  W: [[-2.0608563   0.4500215   1.07126   ]\n",
      " [ 0.12868461  0.00368079 -0.08260597]\n",
      " [ 2.1624072   1.1384122   0.8012814 ]\n",
      " [ 1.2872956   1.798094    0.3582735 ]]  b: [-2.3696294 -1.5163052  4.02525  ]\n",
      "1000 cost:[ 0.31467578 ]  W: [[-2.2194247e+00  5.2480620e-01  1.1872505e+00]\n",
      " [ 1.2104916e-01  2.2530602e-03 -6.3700572e-02]\n",
      " [ 2.2870739e+00  1.1651016e+00  6.7435086e-01]\n",
      " [ 1.2760866e+00  1.7768894e+00  3.7673813e-01]]  b: [-2.71877   -1.5067686  4.317265 ]\n",
      "1100 cost:[ 0.2940651 ]  W: [[-2.3794494e+00  6.0289240e-01  1.3019159e+00]\n",
      " [ 1.1343489e-01  1.7992039e-03 -4.6669681e-02]\n",
      " [ 2.4139566e+00  1.1804117e+00  5.4966992e-01]\n",
      " [ 1.2618423e+00  1.7615577e+00  3.9553818e-01]]  b: [-3.0707407 -1.4864776  4.6082387]\n",
      "1200 cost:[ 0.27486408 ]  W: [[-2.5402710e+00  6.8342382e-01  1.4153155e+00]\n",
      " [ 1.0578023e-01  2.1951224e-03 -3.1149365e-02]\n",
      " [ 2.5425129e+00  1.1864169e+00  4.2694327e-01]\n",
      " [ 1.2451494e+00  1.7517753e+00  4.1428417e-01]]  b: [-3.4232028 -1.4612067  4.8985577]\n",
      "1300 cost:[ 0.256993 ]  W: [[-2.7012234   0.7656698   1.5273727 ]\n",
      " [ 0.0980555   0.00331326 -0.01683669]\n",
      " [ 2.6722546   1.1848459   0.30595824]\n",
      " [ 1.2264194   1.7471064   0.43278506]]  b: [-3.774257  -1.4349895  5.1881986]\n",
      "1400 cost:[ 0.24038175 ]  W: [[-2.8617249   0.8490386   1.6379713 ]\n",
      " [ 0.09024518  0.00503815 -0.00348168]\n",
      " [ 2.8027751   1.1770985   0.18655783]\n",
      " [ 1.2059467   1.7470591   0.45097727]]  b: [-4.1224647 -1.410426   5.476904 ]\n",
      "1500 cost:[ 0.22495884 ]  W: [[-3.021316    0.93306965  1.7470077 ]\n",
      " [ 0.08234144  0.00727238  0.00911508]\n",
      " [ 2.9337478   1.1642857   0.06862048]\n",
      " [ 1.1839474   1.7511266   0.4688732 ]]  b: [-4.466806  -1.3890071  5.7643085]\n",
      "1600 cost:[ 0.21065009 ]  W: [[-3.1796606   1.0174135   1.8544135 ]\n",
      " [ 0.07434265  0.00993548  0.02110824]\n",
      " [ 3.064921    1.1472807  -0.04795259]\n",
      " [ 1.1605827   1.7588122   0.4865283 ]]  b: [-4.806613  -1.3714128  6.050014 ]\n",
      "1700 cost:[ 0.19737951 ]  W: [[-3.336531    1.1018133   1.9601595 ]\n",
      " [ 0.06625185  0.01296212  0.03261423]\n",
      " [ 3.1961017   1.1267695  -0.16324708]\n",
      " [ 1.1359806   1.7696493   0.5040174 ]]  b: [-5.1414924 -1.3577734  6.3336444]\n",
      "1800 cost:[ 0.1850709 ]  W: [[-3.4917886   1.1860826   2.0642543 ]\n",
      " [ 0.05807451  0.01629923  0.04372088]\n",
      " [ 3.3271534   1.103291   -0.27733922]\n",
      " [ 1.110242    1.7832114   0.5214216 ]]  b: [-5.4712596 -1.3478723  6.614875 ]\n",
      "1900 cost:[ 0.17365032 ]  W: [[-3.6453655   1.2700906   2.1667352 ]\n",
      " [ 0.04981806  0.01990322  0.05449446]\n",
      " [ 3.4579794   1.0772753  -0.39030027]\n",
      " [ 1.0834526   1.7991172   0.53881836]]  b: [-5.7958865 -1.3412946  6.8934445]\n",
      "2000 cost:[ 0.16304699 ]  W: [[-3.7972443   1.3537493   2.267659  ]\n",
      " [ 0.0414911   0.02373775  0.06498498]\n",
      " [ 3.5885108   1.0490662  -0.50219786]\n",
      " [ 1.0556871   1.817029    0.5562779 ]]  b: [-6.1154466 -1.3375344  7.16916  ]\n",
      "2100 cost:[ 0.1531943 ]  W: [[-3.9474444   1.4370011   2.3670976 ]\n",
      " [ 0.03310262  0.02777192  0.07523128]\n",
      " [ 3.7187011   1.0189458  -0.6130966 ]\n",
      " [ 1.0270132   1.8366495   0.5738589 ]]  b: [-6.4300947 -1.3360661  7.4418893]\n",
      "2200 cost:[ 0.14403075 ]  W: [[-4.0960083   1.5198127   2.4651322 ]\n",
      " [ 0.02466089  0.03197993  0.08526423]\n",
      " [ 3.8485224   0.98715043 -0.72305846]\n",
      " [ 0.99749136  1.8577222   0.5916105 ]]  b: [-6.7400084 -1.3363836  7.7115617]\n",
      "2300 cost:[ 0.13549933 ]  W: [[-4.243004    1.6021676   2.5618463 ]\n",
      " [ 0.01617452  0.03633866  0.09510922]\n",
      " [ 3.9779568   0.9538797  -0.83214265]\n",
      " [ 0.96717995  1.880023    0.60957056]]  b: [-7.045409  -1.3380288  7.978153 ]\n",
      "2400 cost:[ 0.12754807 ]  W: [[-4.3885007   1.6840612   2.657325  ]\n",
      " [ 0.00765122  0.04082831  0.10478675]\n",
      " [ 4.106993    0.91930634 -0.9404058 ]\n",
      " [ 0.9361342   1.9033585   0.6277678 ]]  b: [-7.3465304 -1.3406011  8.241678 ]\n",
      "2500 cost:[ 0.12012949 ]  W: [[-4.53257465e+00  1.76549745e+00  2.75165367e+00]\n",
      " [-9.01965308e-04  4.54312675e-02  1.14314854e-01]\n",
      " [ 4.23562956e+00  8.83582473e-01 -1.04790163e+00]\n",
      " [ 9.04406905e-01  1.92756236e+00  6.46222651e-01]]  b: [-7.6436024 -1.3437619  8.502185 ]\n",
      "2600 cost:[ 0.11320098 ]  W: [[-4.675305    1.8464863   2.8449113 ]\n",
      " [-0.0094787   0.05013222  0.1237091 ]\n",
      " [ 4.3638635   0.84684396 -1.1546803 ]\n",
      " [ 0.8720473   1.9524912   0.6649487 ]]  b: [-7.936853  -1.3472306  8.759745 ]\n",
      "2700 cost:[ 0.10672327 ]  W: [[-4.816769    1.9270401   2.9371748 ]\n",
      " [-0.01807271  0.05491679  0.13298285]\n",
      " [ 4.491698    0.80921036 -1.2607881 ]\n",
      " [ 0.839104    1.9780203   0.68395305]]  b: [-8.226499  -1.3507857  9.014445 ]\n",
      "2800 cost:[ 0.100661226 ]  W: [[-4.957043    2.0071752   3.0285149 ]\n",
      " [-0.02667921  0.05977335  0.14214826]\n",
      " [ 4.619137    0.7707938  -1.3662677 ]\n",
      " [ 0.8056214   2.004044    0.7032385 ]]  b: [-8.51275  -1.354249  9.266384]\n",
      "2900 cost:[ 0.09498308 ]  W: [[-5.0961976   2.0869076   3.1189995 ]\n",
      " [-0.03529301  0.06469019  0.1512153 ]\n",
      " [ 4.7461796   0.7316904  -1.4711618 ]\n",
      " [ 0.77164364  2.0304701   0.72280294]]  b: [-8.7958    -1.3574915  9.515673 ]\n",
      "3000 cost:[ 0.08965951 ]  W: [[-5.2343016   2.1662533   3.2086897 ]\n",
      " [-0.04391001  0.06965797  0.16019413]\n",
      " [ 4.8728337   0.69199216 -1.5755051 ]\n",
      " [ 0.73721164  2.0572202   0.7426419 ]]  b: [-9.075828  -1.3604162  9.762421 ]\n",
      "3100 cost:[ 0.08466475 ]  W: [[-5.371416    2.2452295   3.2976418 ]\n",
      " [-0.05252634  0.07466773  0.16909339]\n",
      " [ 4.9991007   0.65177983 -1.6793313 ]\n",
      " [ 0.7023643   2.0842261   0.7627487 ]]  b: [-9.353003  -1.3629575 10.006736 ]\n",
      "3200 cost:[ 0.079974756 ]  W: [[-5.5075994   2.323853    3.385907  ]\n",
      " [-0.06113933  0.07971156  0.17791964]\n",
      " [ 5.124984    0.6111272  -1.7826707 ]\n",
      " [ 0.6671375   2.1114302   0.7831134 ]]  b: [-9.62748   -1.3650764 10.248734 ]\n",
      "3300 cost:[ 0.07556808 ]  W: [[-5.6429048   2.402139    3.4735334 ]\n",
      " [-0.0697452   0.08478287  0.1866794 ]\n",
      " [ 5.250485    0.5701013  -1.885551  ]\n",
      " [ 0.6315662   2.138783    0.8037253 ]]  b: [-9.899399  -1.3667507 10.488523 ]\n",
      "3400 cost:[ 0.07142485 ]  W: [[-5.7773824   2.4801006   3.5605633 ]\n",
      " [-0.07834189  0.08987591  0.19537893]\n",
      " [ 5.3756075   0.5287621  -1.9879965 ]\n",
      " [ 0.5956822   2.1662443   0.82457274]]  b: [-10.168888   -1.3679745  10.726208 ]\n",
      "3500 cost:[ 0.0675271 ]  W: [[-5.9110765   2.5577533   3.6470366 ]\n",
      " [-0.08692713  0.09498525  0.20402382]\n",
      " [ 5.500355    0.4871632  -2.0900295 ]\n",
      " [ 0.55951506  2.1937776   0.8456437 ]]  b: [-10.4360695  -1.3687567  10.961887 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600 cost:[ 0.06385824 ]  W: [[-6.0440283   2.6351087   3.7329879 ]\n",
      " [-0.09549897  0.10010631  0.21261844]\n",
      " [ 5.6247296   0.44535246 -2.1916685 ]\n",
      " [ 0.52309287  2.2213547   0.8669257 ]]  b: [-10.70105   -1.369114  11.19566 ]\n",
      "3700 cost:[ 0.06040318 ]  W: [[-6.176277    2.7121787   3.8184495 ]\n",
      " [-0.10405619  0.10523541  0.2211667 ]\n",
      " [ 5.748734    0.4033722  -2.2929323 ]\n",
      " [ 0.48644093  2.2489507   0.8884058 ]]  b: [-10.963928   -1.3690696  11.427615 ]\n",
      "3800 cost:[ 0.057148032 ]  W: [[-6.307857    2.7889762   3.9034507 ]\n",
      " [-0.11259708  0.11036908  0.22967245]\n",
      " [ 5.872369    0.36126044 -2.3938372 ]\n",
      " [ 0.44958264  2.276545    0.9100709 ]]  b: [-11.224799   -1.3686513  11.657841 ]\n",
      "3900 cost:[ 0.05407995 ]  W: [[-6.4387984   2.865511    3.988019  ]\n",
      " [-0.12112138  0.11550506  0.23813862]\n",
      " [ 5.99564     0.3190506  -2.494397  ]\n",
      " [ 0.41253898  2.304123    0.9319085 ]]  b: [-11.4837475  -1.367889   11.886414 ]\n",
      "4000 cost:[ 0.05118698 ]  W: [[-6.569132    2.9417915   4.072178  ]\n",
      " [-0.12962751  0.1206399   0.24656829]\n",
      " [ 6.118547    0.27676854 -2.5946245 ]\n",
      " [ 0.3753315   2.3316689   0.953906  ]]  b: [-11.740847   -1.3668194  12.113414 ]\n",
      "4100 cost:[ 0.04845817 ]  W: [[-6.6988845   3.0178292   4.1559477 ]\n",
      " [-0.13811575  0.12577271  0.25496376]\n",
      " [ 6.2410955   0.23444258 -2.6945322 ]\n",
      " [ 0.33797574  2.359175    0.9760521 ]]  b: [-11.996171   -1.3654734  12.33891  ]\n",
      "4200 cost:[ 0.045883372 ]  W: [[-6.8280826   3.0936322   4.2393537 ]\n",
      " [-0.14658503  0.13090086  0.26332718]\n",
      " [ 6.363289    0.19209146 -2.79413   ]\n",
      " [ 0.30049023  2.3866313   0.99833524]]  b: [-12.24979    -1.3638868  12.562973 ]\n",
      "4300 cost:[ 0.043453135 ]  W: [[-6.956747    3.1692097   4.3224096 ]\n",
      " [-0.15503566  0.13602413  0.27166063]\n",
      " [ 6.485131    0.14973544 -2.8934286 ]\n",
      " [ 0.26288864  2.414034    1.0207446 ]]  b: [-12.501765   -1.3620919  12.785664 ]\n",
      "4400 cost:[ 0.041158695 ]  W: [[-7.084902    3.2445683   4.4051356 ]\n",
      " [-0.16346708  0.14114085  0.27996543]\n",
      " [ 6.606622    0.10738895 -2.9924371 ]\n",
      " [ 0.22518519  2.4413764   1.0432698 ]]  b: [-12.752154   -1.3601214  13.00704  ]\n",
      "4500 cost:[ 0.038991757 ]  W: [[-7.212567    3.3197188   4.4875474 ]\n",
      " [-0.17187938  0.14625025  0.2882436 ]\n",
      " [ 6.7277713   0.06506415 -3.0911634 ]\n",
      " [ 0.18739258  2.4686575   1.0659015 ]]  b: [-13.001014   -1.3580067  13.227159 ]\n",
      "4600 cost:[ 0.036944844 ]  W: [[-7.3397617   3.3946657   4.569659  ]\n",
      " [-0.1802729   0.1513519   0.2964961 ]\n",
      " [ 6.8485813   0.02277365 -3.1896167 ]\n",
      " [ 0.14952077  2.495875    1.0886297 ]]  b: [-13.248391   -1.355776   13.4460745]\n",
      "4700 cost:[ 0.035010807 ]  W: [[-7.4665036   3.4694176   4.651485  ]\n",
      " [-0.18864782  0.15644525  0.30472434]\n",
      " [ 6.9690557  -0.01947449 -3.2878036 ]\n",
      " [ 0.11157998  2.5230274   1.1114471 ]]  b: [-13.494338  -1.353457  13.663833]\n",
      "4800 cost:[ 0.03318291 ]  W: [[-7.59281     3.5439816   4.7330403 ]\n",
      " [-0.19700474  0.16153075  0.3129298 ]\n",
      " [ 7.089204   -0.06167189 -3.3857315 ]\n",
      " [ 0.07357855  2.5501173   1.1343453 ]]  b: [-13.7389    -1.351075  13.88048 ]\n",
      "4900 cost:[ 0.031454995 ]  W: [[-7.718697    3.6183653   4.8143344 ]\n",
      " [-0.20534338  0.16660774  0.32111377]\n",
      " [ 7.209029   -0.10381397 -3.4834073 ]\n",
      " [ 0.03552481  2.5771437   1.1573166 ]]  b: [-13.982121   -1.3486555  14.096061 ]\n",
      "5000 cost:[ 0.029821288 ]  W: [[-7.8441830e+00  3.6925721e+00  4.8953791e+00]\n",
      " [-2.1366470e-01  1.7167602e-01  3.2927620e-01]\n",
      " [ 7.3285356e+00 -1.4589632e-01 -3.5808389e+00]\n",
      " [-2.5742422e-03  2.6041079e+00  1.1803545e+00]]  b: [-14.22404    -1.3462191  14.310619 ]\n",
      "****** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "print('****** Start Learning!!')\n",
    "for step in range(5001):\n",
    "    # cost를 minimize 한다\n",
    "    optimizer.minimize(cost_func,var_list=[W,b]) # W,b를 업데이트\n",
    "    if step % 100 == 0:\n",
    "        print('%04d'%step,'cost:[',cost_func().numpy(),']',\n",
    "             ' W:',W.numpy(),' b:',b.numpy())\n",
    "        \n",
    "print('****** Learning Finished!!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: [[-7.8441830e+00  3.6925721e+00  4.8953791e+00]\n",
      " [-2.1366470e-01  1.7167602e-01  3.2927620e-01]\n",
      " [ 7.3285356e+00 -1.4589632e-01 -3.5808389e+00]\n",
      " [-2.5742422e-03  2.6041079e+00  1.1803545e+00]]\n",
      "bias: [-14.22404    -1.3462191  14.310619 ]\n"
     ]
    }
   ],
   "source": [
    "# Weight과 bias 출력\n",
    "print('Weight:',W.numpy())  # (4,3)\n",
    "print('bias:', b.numpy())   # (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 1 1 1 0 0]\n",
      "[[6.7201891e-15 4.4788094e-06 9.9999547e-01]\n",
      " [3.0885475e-11 6.2573748e-03 9.9374264e-01]\n",
      " [8.2859493e-18 3.1583805e-02 9.6841621e-01]\n",
      " [5.7242741e-16 9.7510344e-01 2.4896599e-02]\n",
      " [5.8690630e-02 9.3963599e-01 1.6734032e-03]\n",
      " [3.0668104e-02 9.6914285e-01 1.8900630e-04]\n",
      " [9.2271829e-01 7.7280879e-02 9.1235347e-07]\n",
      " [9.9905401e-01 9.4603549e-04 1.0147023e-10]]\n",
      "[2 2 2 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "# tf.argmax() : 값이 가장 큰 요소의 인덱스 값을 반환\n",
    "def predict(X):\n",
    "    return tf.argmax(hypothesis(X),axis=1)\n",
    "\n",
    "# 학습 데이터를 검증 데이터로 동일하게 사용하는 경우\n",
    "x_test = x_train\n",
    "y_test = y_train\n",
    "\n",
    "preds = predict(x_test)\n",
    "print(preds.numpy())\n",
    "print(hypothesis(x_test).numpy())\n",
    "print(tf.argmax(y_test,1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
